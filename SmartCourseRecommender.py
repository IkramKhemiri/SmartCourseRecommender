# app.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import warnings
warnings.filterwarnings('ignore')

# TÃ©lÃ©chargement des stopwords NLTK
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# =============================================================================
# CLASSES DU SYSTÃˆME DE RECOMMANDATION
# =============================================================================

class DataPreprocessor:
    """Classe de prÃ©traitement des donnÃ©es"""
    
    def __init__(self):
        self.stemmer = PorterStemmer()
        self.stop_words = set(stopwords.words('english'))
    
    def preprocess_data(self, df):
        """PrÃ©traitement complet du dataset"""
        df_clean = df.copy()
        
        # Nettoyage des noms de colonnes
        df_clean.columns = [col.strip().replace(' ', '_').lower() for col in df_clean.columns]
        
        # Remplissage des valeurs manquantes
        text_columns = ['course_title', 'what_you_will_learn', 'skill_gain', 'keyword', 'instructor', 'offered_by']
        for col in text_columns:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].fillna('').astype(str)
        
        # Nettoyage des textes
        for col in text_columns:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].apply(self.clean_text)
        
        # Conversion des ratings
        df_clean['rating'] = pd.to_numeric(df_clean['rating'], errors='coerce').fillna(0)
        df_clean['number_of_review'] = pd.to_numeric(df_clean['number_of_review'], errors='coerce').fillna(0)
        
        # Nettoyage du niveau
        df_clean['level'] = df_clean['level'].fillna('Not Specified').astype(str)
        
        # Extraction de la durÃ©e en semaines
        df_clean['duration_weeks'] = df_clean['duration_to_complete_(approx.)'].apply(self.extract_duration_weeks)
        
        # CrÃ©ation de tags combinÃ©s pour la recherche sÃ©mantique
        df_clean['combined_tags'] = (
            df_clean['course_title'] + " " + 
            df_clean['what_you_will_learn'] + " " + 
            df_clean['skill_gain'] + " " + 
            df_clean['keyword'] + " " +
            df_clean['instructor'] + " " +
            df_clean['offered_by']
        )
        
        # S'assurer qu'il n'y a pas de NaN dans combined_tags
        df_clean['combined_tags'] = df_clean['combined_tags'].fillna('').astype(str)
        
        # Filtrer les documents vides
        df_clean = df_clean[df_clean['combined_tags'].str.strip() != '']
        
        return df_clean
    
    def clean_text(self, text):
        """Nettoie et normalise le texte"""
        if pd.isna(text) or text == 'Not specified' or text == 'nan':
            return ""
        text = str(text).lower()
        text = re.sub(r'[^\w\s]', ' ', text)  # Supprime la ponctuation
        text = re.sub(r'\s+', ' ', text).strip()  # Supprime les espaces multiples
        return text
    
    def extract_duration_weeks(self, duration_str):
        """Extrait la durÃ©e en semaines"""
        if pd.isna(duration_str):
            return 8
        
        try:
            duration_str = str(duration_str).lower()
            
            if 'hour' in duration_str:
                hours = int(''.join(filter(str.isdigit, duration_str.split()[0])))
                return max(1, hours // 10)  # Approximation: 10 heures = 1 semaine
            elif 'week' in duration_str:
                return int(''.join(filter(str.isdigit, duration_str.split()[0])))
            elif 'month' in duration_str:
                months = int(''.join(filter(str.isdigit, duration_str.split()[0])))
                return months * 4
            else:
                # Si c'est un nombre, suppose que c'est en semaines
                return float(duration_str)
        except:
            return 8  # DurÃ©e par dÃ©faut

class ContentBasedRecommender:
    """SystÃ¨me de recommandation basÃ© sur le contenu"""
    
    def __init__(self, df):
        self.df = df
        self.tfidf_vectorizer = None
        self.tfidf_matrix = None
        self._build_tfidf_model()
    
    def _build_tfidf_model(self):
        """Construit le modÃ¨le TF-IDF"""
        # S'assurer que tous les documents sont des strings non vides
        documents = self.df['combined_tags'].fillna('').astype(str)
        valid_docs = documents[documents.str.strip() != '']
        
        if len(valid_docs) == 0:
            return
        
        self.tfidf_vectorizer = TfidfVectorizer(
            stop_words='english',
            max_features=5000,
            ngram_range=(1, 2),
            min_df=1,
            max_df=0.9
        )
        
        try:
            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(valid_docs)
        except Exception as e:
            st.error(f"âŒ Erreur lors de la construction du modÃ¨le TF-IDF: {e}")
    
    def semantic_search(self, query, top_n=10):
        """Recherche sÃ©mantique basÃ©e sur la requÃªte"""
        if not query or query.strip() == "" or self.tfidf_vectorizer is None:
            return self.df.head(0)
        
        try:
            query_vec = self.tfidf_vectorizer.transform([query])
            similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()
            
            # Seuil de similaritÃ© minimum
            threshold = 0.05
            similar_indices = np.where(similarities >= threshold)[0]
            
            if len(similar_indices) == 0:
                return self.df.head(0)
            
            # Tri par similaritÃ©
            results_df = self.df.iloc[similar_indices].copy()
            results_df['similarity_score'] = similarities[similar_indices]
            results_df = results_df.sort_values('similarity_score', ascending=False).head(top_n)
            
            return results_df
        except Exception as e:
            return self.df.head(0)
    
    def find_similar_courses(self, course_title, top_n=8):
        """Trouve des cours similaires Ã  un cours donnÃ©"""
        try:
            if self.tfidf_matrix is None:
                return self.df.head(0)
                
            course_idx = self.df[self.df['course_title'] == course_title].index[0]
            similarities = cosine_similarity(
                self.tfidf_matrix[course_idx], 
                self.tfidf_matrix
            ).flatten()
            
            # Exclure le cours lui-mÃªme
            similar_indices = similarities.argsort()[-top_n-1:-1][::-1]
            results_df = self.df.iloc[similar_indices].copy()
            results_df['similarity_score'] = similarities[similar_indices]
            
            return results_df
        except:
            return self.df.head(0)

class KnowledgeBasedRecommender:
    """SystÃ¨me de recommandation basÃ© sur les connaissances"""
    
    def __init__(self, df):
        self.df = df
        self._calculate_utility_scores()
    
    def _calculate_utility_scores(self):
        """Calcule les scores d'utilitÃ© pour tous les cours"""
        # Score de popularitÃ© bayÃ©sien
        C = self.df['rating'].mean() if len(self.df) > 0 else 3.0
        m = self.df['number_of_review'].quantile(0.6) if len(self.df) > 0 else 10
        v = self.df['number_of_review']
        R = self.df['rating']
        
        self.df['bayesian_score'] = (v / (v + m)) * R + (m / (v + m)) * C
        
        # Score de durÃ©e (plus court = mieux)
        max_duration = self.df['duration_weeks'].max() if len(self.df) > 0 else 20
        self.df['duration_score'] = 1 - (self.df['duration_weeks'] / max_duration)
        
        # Score d'utilitÃ© global
        self.df['utility_score'] = (
            0.5 * self.df['bayesian_score'] +
            0.3 * (self.df['rating'] / 5.0) +
            0.2 * self.df['duration_score']
        )
    
    def constraint_based_filter(self, constraints):
        """Filtrage basÃ© sur les contraintes"""
        candidates = self.df.copy()
        
        # Niveau
        if constraints.get('level') and constraints['level'] != 'All':
            candidates = candidates[candidates['level'] == constraints['level']]
        
        # Note minimale
        if constraints.get('min_rating'):
            candidates = candidates[candidates['rating'] >= constraints['min_rating']]
        
        # DurÃ©e maximale
        if constraints.get('max_duration_weeks'):
            candidates = candidates[
                candidates['duration_weeks'] <= constraints['max_duration_weeks']
            ]
        
        # CompÃ©tences recherchÃ©es
        if constraints.get('required_skills'):
            skill_filter = candidates['skill_gain'].apply(
                lambda x: any(skill.lower() in str(x).lower() 
                            for skill in constraints['required_skills'])
            )
            candidates = candidates[skill_filter]
        
        # Organisation
        if constraints.get('offered_by'):
            candidates = candidates[
                candidates['offered_by'].str.contains(
                    constraints['offered_by'], case=False, na=False
                )
            ]
        
        return candidates
    
    def get_trending_courses(self, top_n=10):
        """Retourne les cours tendances"""
        if len(self.df) == 0:
            return self.df
        return self.df.nlargest(top_n, 'utility_score')

class CollaborativeLightRecommender:
    """Recommandation collaborative lÃ©gÃ¨re (item-item)"""
    
    def __init__(self, tfidf_matrix, df):
        self.similarity_matrix = cosine_similarity(tfidf_matrix) if tfidf_matrix is not None else None
        self.df = df
    
    def item_item_recommendations(self, liked_courses, top_n=10):
        """Recommandations basÃ©es sur des cours aimÃ©s"""
        if not liked_courses or self.similarity_matrix is None:
            return pd.DataFrame()
        
        all_similarities = []
        
        for course_title in liked_courses:
            try:
                course_idx = self.df[self.df['course_title'] == course_title].index[0]
                similarities = list(enumerate(self.similarity_matrix[course_idx]))
                all_similarities.extend(similarities)
            except:
                continue
        
        if not all_similarities:
            return pd.DataFrame()
        
        # AgrÃ©gation des similaritÃ©s
        similarity_scores = {}
        for idx, score in all_similarities:
            if idx not in similarity_scores:
                similarity_scores[idx] = 0
            similarity_scores[idx] += score
        
        # Exclusion des cours dÃ©jÃ  aimÃ©s
        liked_indices = []
        for course in liked_courses:
            try:
                liked_indices.append(self.df[self.df['course_title'] == course].index[0])
            except:
                continue
        
        for idx in liked_indices:
            if idx in similarity_scores:
                del similarity_scores[idx]
        
        # SÃ©lection des meilleurs
        if not similarity_scores:
            return pd.DataFrame()
            
        top_indices = sorted(similarity_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]
        results_df = self.df.iloc[[idx for idx, score in top_indices]].copy()
        results_df['collaborative_score'] = [score for idx, score in top_indices]
        
        return results_df

class HybridCourseRecommender:
    """SystÃ¨me de recommandation hybride principal"""
    
    def __init__(self, df):
        self.df = df
        self.preprocessor = DataPreprocessor()
        self.df_clean = self.preprocessor.preprocess_data(df)
        
        # VÃ©rifier que le dataset n'est pas vide aprÃ¨s nettoyage
        if len(self.df_clean) == 0:
            return
        
        # Initialisation des recommandeurs
        self.content_recommender = ContentBasedRecommender(self.df_clean)
        self.knowledge_recommender = KnowledgeBasedRecommender(self.df_clean)
        self.collaborative_recommender = CollaborativeLightRecommender(
            self.content_recommender.tfidf_matrix, self.df_clean
        )
    
    def hybrid_recommend(self, user_input):
        """
        GÃ©nÃ¨re des recommandations hybrides
        """
        # VÃ©rifier que le systÃ¨me est initialisÃ©
        if len(self.df_clean) == 0:
            return pd.DataFrame()
        
        strategy = user_input.get('strategy', 'cascade')
        
        if strategy == 'cascade':
            return self._cascade_hybrid(user_input)
        elif strategy == 'weighted':
            return self._weighted_hybrid(user_input)
        elif strategy == 'mixed':
            return self._mixed_hybrid(user_input)
        else:
            return self._cascade_hybrid(user_input)
    
    def _cascade_hybrid(self, user_input):
        """StratÃ©gie cascade : filtrage progressif"""
        # Ã‰tape 1: Filtrage knowledge-based
        filtered_courses = self.knowledge_recommender.constraint_based_filter(
            user_input.get('filters', {})
        )
        
        # Ã‰tape 2: Recherche content-based
        content_results = pd.DataFrame()
        if user_input.get('search_query'):
            content_results = self.content_recommender.semantic_search(
                user_input['search_query'], 
                top_n=20
            )
        
        # Fusion des rÃ©sultats
        if not filtered_courses.empty and not content_results.empty:
            all_candidates = pd.concat([filtered_courses, content_results]).drop_duplicates()
        elif not filtered_courses.empty:
            all_candidates = filtered_courses
        else:
            all_candidates = content_results
        
        # Ã‰tape 3: Boost collaboratif
        collaborative_results = pd.DataFrame()
        if user_input.get('liked_courses') and not all_candidates.empty:
            collaborative_results = self.collaborative_recommender.item_item_recommendations(
                user_input['liked_courses'], top_n=15
            )
        
        # Fusion finale
        if not collaborative_results.empty:
            final_candidates = pd.concat([all_candidates, collaborative_results]).drop_duplicates()
        else:
            final_candidates = all_candidates
        
        # Ã‰tape 4: Classement hybride
        if not final_candidates.empty:
            final_ranking = self._hybrid_ranking(final_candidates, user_input)
            return final_ranking.head(15)
        else:
            # Fallback: cours tendances
            return self.knowledge_recommender.get_trending_courses(10)
    
    def _weighted_hybrid(self, user_input):
        """StratÃ©gie pondÃ©rÃ©e : combinaison linÃ©aire des scores"""
        return self._cascade_hybrid(user_input)
    
    def _mixed_hybrid(self, user_input):
        """StratÃ©gie mixte : rÃ©sultats sÃ©parÃ©s par type"""
        recommendations = {}
        
        # Content-based
        if user_input.get('search_query'):
            recommendations['content_based'] = self.content_recommender.semantic_search(
                user_input['search_query'], top_n=5
            )
        
        # Knowledge-based
        recommendations['knowledge_based'] = self.knowledge_recommender.constraint_based_filter(
            user_input.get('filters', {})
        ).head(5)
        
        # Collaborative
        if user_input.get('liked_courses'):
            recommendations['collaborative'] = self.collaborative_recommender.item_item_recommendations(
                user_input['liked_courses'], top_n=5
            )
        
        # Trending
        recommendations['trending'] = self.knowledge_recommender.get_trending_courses(5)
        
        return recommendations
    
    def _hybrid_ranking(self, candidates, user_input):
        """Classement final avec scores hybrides"""
        candidates = candidates.copy()
        
        # Score de contenu
        if user_input.get('search_query'):
            content_scores = []
            for idx, course in candidates.iterrows():
                try:
                    course_idx = self.df_clean[self.df_clean['course_title'] == course['course_title']].index[0]
                    similarity = self.content_recommender.tfidf_matrix[course_idx]
                    query_vec = self.content_recommender.tfidf_vectorizer.transform([user_input['search_query']])
                    content_score = cosine_similarity(query_vec, similarity).flatten()[0]
                    content_scores.append(content_score)
                except:
                    content_scores.append(0.3)
            candidates['content_score'] = content_scores
        else:
            candidates['content_score'] = 0.3
        
        # Score collaboratif
        if user_input.get('liked_courses'):
            collab_scores = []
            for idx, course in candidates.iterrows():
                try:
                    course_idx = self.df_clean[self.df_clean['course_title'] == course['course_title']].index[0]
                    total_similarity = 0
                    count = 0
                    for liked_course in user_input['liked_courses']:
                        try:
                            liked_idx = self.df_clean[self.df_clean['course_title'] == liked_course].index[0]
                            similarity = self.collaborative_recommender.similarity_matrix[course_idx, liked_idx]
                            total_similarity += similarity
                            count += 1
                        except:
                            continue
                    collab_scores.append(total_similarity / count if count > 0 else 0.1)
                except:
                    collab_scores.append(0.1)
            candidates['collab_score'] = collab_scores
        else:
            candidates['collab_score'] = 0.2
        
        # Score de popularitÃ©
        candidates['popularity_score'] = candidates['utility_score']
        
        # Score hybride final
        candidates['hybrid_score'] = (
            0.4 * candidates['content_score'] +
            0.3 * candidates['popularity_score'] +
            0.3 * candidates['collab_score']
        )
        
        return candidates.sort_values('hybrid_score', ascending=False)

# =============================================================================
# FONCTIONS UTILITAIRES ET VISUALISATIONS
# =============================================================================

def generate_explanation(course, user_input):
    """GÃ©nÃ¨re une explication personnalisÃ©e pour la recommandation"""
    explanations = []
    
    if user_input.get('search_query'):
        explanations.append(f"ğŸ” **Correspond Ã  votre recherche :** \"{user_input['search_query']}\"")
    
    filters = user_input.get('filters', {})
    if filters.get('level') and filters['level'] != 'All':
        explanations.append(f"ğŸ¯ **Niveau adaptÃ© :** {filters['level']}")
    
    if filters.get('min_rating'):
        explanations.append(f"â­ **DÃ©passe la note minimale :** {filters['min_rating']}+")
    
    if user_input.get('liked_courses'):
        explanations.append("ğŸ“š **LiÃ© aux cours que vous avez apprÃ©ciÃ©s**")
    
    # Explications basÃ©es sur les mÃ©triques du cours
    if course['rating'] >= 4.5:
        explanations.append("ğŸŒŸ **Excellente notation communautaire**")
    elif course['rating'] >= 4.0:
        explanations.append("ğŸ‘ **TrÃ¨s bien notÃ© par les apprenants**")
    
    if course['number_of_review'] > 1000:
        explanations.append("ğŸ“Š **Populaire avec de nombreux avis**")
    
    if course['duration_weeks'] <= 4:
        explanations.append("âš¡ **Formation intensive et courte**")
    elif course['duration_weeks'] <= 8:
        explanations.append("ğŸ“… **DurÃ©e modÃ©rÃ©e bien Ã©quilibrÃ©e**")
    
    if len(explanations) == 0:
        explanations.append("ğŸ‰ **DÃ©couverte optimisÃ©e par notre intelligence artificielle**")
    
    return "\n\n".join(explanations)

def create_radar_chart(course, max_values, course_index):
    """CrÃ©e un graphique radar pour visualiser les caractÃ©ristiques du cours"""
    categories = ['QualitÃ©', 'PopularitÃ©', 'IntensitÃ©', 'DurÃ©e', 'Pertinence']
    
    # Normalisation des valeurs
    quality = (course['rating'] / 5.0) * 100
    popularity = min(100, (course['number_of_review'] / max(1, max_values['max_reviews'])) * 100)
    intensity = 100 - (course['duration_weeks'] / max(1, max_values['max_duration'])) * 100
    duration_score = max(20, 100 - (course['duration_weeks'] / max(1, max_values['max_duration'])) * 80)
    relevance = min(100, course.get('hybrid_score', 0.5) * 100)
    
    values = [quality, popularity, intensity, duration_score, relevance]
    
    fig = go.Figure(data=go.Scatterpolar(
        r=values + [values[0]],  # Fermer le radar
        theta=categories + [categories[0]],
        fill='toself',
        fillcolor='rgba(100, 150, 255, 0.3)',
        line=dict(color='rgb(100, 150, 255)'),
        name=course['course_title'][:30] + "..."
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )),
        showlegend=False,
        height=300,
        margin=dict(l=50, r=50, t=50, b=50),
        title=f"Profil du Cours #{course_index + 1}"
    )
    
    return fig




# Ajoutez cette fonction utilitaire pour crÃ©er des graphiques radar avec des clÃ©s uniques
def display_radar_chart(course, max_values, chart_key):
    """Affiche un graphique radar avec une clÃ© unique"""
    categories = ['QualitÃ©', 'PopularitÃ©', 'IntensitÃ©', 'DurÃ©e', 'Pertinence']
    
    # Normalisation des valeurs
    quality = (course['rating'] / 5.0) * 100
    popularity = min(100, (course['number_of_review'] / max(1, max_values['max_reviews'])) * 100)
    intensity = 100 - (course['duration_weeks'] / max(1, max_values['max_duration'])) * 100
    duration_score = max(20, 100 - (course['duration_weeks'] / max(1, max_values['max_duration'])) * 80)
    relevance = min(100, course.get('hybrid_score', 0.5) * 100)
    
    values = [quality, popularity, intensity, duration_score, relevance]
    
    fig = go.Figure(data=go.Scatterpolar(
        r=values + [values[0]],
        theta=categories + [categories[0]],
        fill='toself',
        fillcolor='rgba(100, 150, 255, 0.3)',
        line=dict(color='rgb(100, 150, 255)'),
        name=course['course_title'][:30] + "..."
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )),
        showlegend=False,
        height=300,
        margin=dict(l=50, r=50, t=50, b=50),
        title=f"Profil du Cours"
    )
    
    # CLÃ‰ UNIQUE AJOUTÃ‰E ICI
    st.plotly_chart(fig, use_container_width=True, key=chart_key)




# =============================================================================
# DASHBOARD STREAMLIT PRINCIPAL
# =============================================================================

def main():
    # Configuration de la page
    st.set_page_config(
        page_title="Smart Course Recommender",
        page_icon="ğŸ“",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # CSS personnalisÃ©
    st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
    }
    .course-card {
        background-color: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
        border-left: 4px solid #ff6b6b;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Header principal
    st.markdown('<h1 class="main-header">ğŸ“ Smart Course Recommender</h1>', unsafe_allow_html=True)
    st.markdown("### SystÃ¨me de Recommandation Hybride Intelligent pour l'Ã‰ducation")
    st.markdown("---")
    
    # Initialisation du systÃ¨me
    if 'recommender' not in st.session_state:
        # Chargement des donnÃ©es
        @st.cache_data
        def load_data():
            try:
                df = pd.read_csv("CourseraDataset-Clean.csv")
                st.success(f"âœ… Dataset chargÃ© avec succÃ¨s! {len(df)} cours disponibles.")
                return df
            except Exception as e:
                st.error(f"âŒ Erreur lors du chargement du dataset: {e}")
                return pd.DataFrame()
            
        df = load_data()
        if not df.empty:
            st.session_state.recommender = HybridCourseRecommender(df)
            st.session_state.data_loaded = True
        else:
            st.session_state.data_loaded = False
            return
    
    if not st.session_state.get('data_loaded', False):
        st.warning("ğŸ“ Le dataset n'a pas pu Ãªtre chargÃ©. VÃ©rifiez le fichier 'CourseraDataset-Clean.csv'")
        return
    
    # SIDEBAR - CONFIGURATION
    with st.sidebar:
        st.header("âš™ï¸ Configuration du SystÃ¨me")
        
        # StratÃ©gie d'hybridation
        st.subheader("ğŸ¯ StratÃ©gie de Recommandation")
        strategy = st.selectbox(
            "MÃ©thode d'hybridation",
            ["cascade", "mixed", "weighted"],
            format_func=lambda x: {
                "cascade": "Cascade (RecommandÃ©)",
                "mixed": "Mixte (RÃ©sultats sÃ©parÃ©s)", 
                "weighted": "PondÃ©rÃ©e"
            }[x]
        )
        
        # Section Knowledge-Based
        st.subheader("ğŸ“ Filtres Knowledge-Based")
        level = st.selectbox(
            "Niveau de difficultÃ©",
            ["All", "Beginner", "Intermediate", "Advanced", "Mixed"]
        )
        
        min_rating = st.slider(
            "Note minimale requise",
            min_value=3.0,
            max_value=5.0,
            value=4.0,
            step=0.1
        )
        
        max_duration = st.selectbox(
            "DurÃ©e maximale",
            ["All", "4 weeks", "8 weeks", "12 weeks", "16 weeks", "20+ weeks"]
        )
        
        # CompÃ©tences
        st.subheader("ğŸ› ï¸ CompÃ©tences RecherchÃ©es")
        skills_input = st.text_input(
            "CompÃ©tences (sÃ©parÃ©es par des virgules)",
            placeholder="Ex: python, machine learning, data analysis"
        )
        required_skills = [s.strip() for s in skills_input.split(',')] if skills_input else []
        
        # Section Collaborative
        st.subheader("â¤ï¸ PrÃ©fÃ©rences Personnelles")
        available_courses = st.session_state.recommender.df_clean['course_title'].head(50).tolist()
        liked_courses = st.multiselect(
            "Cours que vous avez apprÃ©ciÃ©s",
            available_courses,
            help="SÃ©lectionnez les cours que vous avez aimÃ©s pour des recommandations personnalisÃ©es"
        )
        
        # Section Recherche
        st.subheader("ğŸ” Recherche SÃ©mantique")
        search_query = st.text_input(
            "Description de ce que vous cherchez",
            placeholder="Ex: cours python pour dÃ©butants avec projets pratiques"
        )
        
        # Boutons d'action
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¯ GÃ©nÃ©rer Recommendations", type="primary", use_container_width=True):
                st.session_state.generate_recos = True
        with col2:
            if st.button("ğŸ”„ RÃ©initialiser", use_container_width=True):
                st.session_state.generate_recos = False
                st.rerun()
    
    # CONTENU PRINCIPAL
    if st.session_state.get('generate_recos', False):
        show_recommendations_page(strategy, level, min_rating, max_duration, required_skills, liked_courses, search_query)
    else:
        show_welcome_page()

def show_welcome_page():
    """Page d'accueil avec prÃ©sentation du systÃ¨me"""
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸŒŸ Bienvenue dans le Smart Course Recommender!")
        
        st.markdown("""
        ### ğŸ¯ Un SystÃ¨me de Recommandation Hybride AvancÃ©
        
        Notre plateforme combine **4 approches intelligentes** pour vous trouver les meilleurs cours :
        """)
        
        # Features
        features = [
            ("ğŸ” **Recherche SÃ©mantique**", "Comprend le sens de votre recherche, pas juste les mots-clÃ©s"),
            ("ğŸ“ **Filtres Intelligents**", "Adapte les recommandations Ã  votre niveau et disponibilitÃ©"),
            ("â¤ï¸ **Apprentissage Collaboratif**", "S'appuie sur vos prÃ©fÃ©rences pour affiner les suggestions"),
            ("â­ **Analyse de PopularitÃ©**", "ConsidÃ¨re les notes et avis de la communautÃ©"),
            ("ğŸ¤ **Hybridation AvancÃ©e**", "Combine toutes ces approches pour des rÃ©sultats optimaux")
        ]
        
        for feature, description in features:
            with st.container():
                col_f1, col_f2 = st.columns([1, 4])
                with col_f1:
                    st.markdown(f"**{feature}**")
                with col_f2:
                    st.markdown(description)
            st.write("")
        
        st.info("""
        ğŸ’¡ **Pour commencer :** 
        1. Configurez vos prÃ©fÃ©rences dans la sidebar 
        2. Cliquez sur **'GÃ©nÃ©rer Recommendations'**
        3. DÃ©couvrez des cours parfaitement adaptÃ©s Ã  vos besoins !
        """)
    
    with col2:
        st.header("ğŸ“Š Statistiques du Catalogue")
        
        # MÃ©triques globales
        recommender = st.session_state.recommender
        df = recommender.df_clean
        
        if len(df) > 0:
            col_m1, col_m2 = st.columns(2)
            with col_m1:
                st.metric("ğŸ“š Cours Disponibles", len(df))
                st.metric("â­ Note Moyenne", f"{df['rating'].mean():.2f}")
            with col_m2:
                st.metric("ğŸ“ Niveaux", df['level'].nunique())
                st.metric("ğŸ¢ Organisations", df['offered_by'].nunique())
            
            # Graphique des niveaux
            level_counts = df['level'].value_counts()
            fig_levels = px.pie(
                values=level_counts.values,
                names=level_counts.index,
                title="RÃ©partition par Niveau"
            )
            st.plotly_chart(fig_levels, use_container_width=True)
        else:
            st.warning("Aucune donnÃ©e disponible pour les statistiques")
    
    # Section tÃ©moignages
    st.markdown("---")
    st.header("ğŸ­ ScÃ©narios d'Utilisation")
    
    scenarios = [
        {
            "title": "ğŸš€ DÃ©butant en Programmation",
            "description": "Je veux apprendre Python from scratch avec des projets pratiques",
            "filters": {"level": "Beginner", "skills": ["python", "programming"]}
        },
        {
            "title": "ğŸ“Š Professionnel en Reconversion", 
            "description": "Je cherche une formation Data Science complÃ¨te avec certification",
            "filters": {"level": "Intermediate", "duration": "8-12 weeks"}
        },
        {
            "title": "ğŸ¯ SpÃ©cialisation AvancÃ©e",
            "description": "Je veux me perfectionner en Machine Learning avec des cas rÃ©els",
            "filters": {"level": "Advanced", "min_rating": 4.5}
        }
    ]
    
    cols = st.columns(3)
    for i, scenario in enumerate(scenarios):
        with cols[i]:
            with st.container():
                st.markdown(f"### {scenario['title']}")
                st.markdown(scenario['description'])
                st.caption("ğŸ’¡ IdÃ©al pour ce type de profil")

def show_recommendations_page(strategy, level, min_rating, max_duration, required_skills, liked_courses, search_query):
    """Page de rÃ©sultats des recommandations"""
    
    # PrÃ©paration des inputs utilisateur
    user_input = {
        'strategy': strategy,
        'search_query': search_query,
        'filters': {
            'level': level if level != "All" else None,
            'min_rating': min_rating,
            'max_duration_weeks': parse_duration(max_duration) if max_duration != "All" else None,
            'required_skills': required_skills
        },
        'liked_courses': liked_courses
    }
    
    # GÃ©nÃ©ration des recommandations
    with st.spinner("ğŸ”® GÃ©nÃ©ration des recommandations personnalisÃ©es..."):
        recommendations = st.session_state.recommender.hybrid_recommend(user_input)
    
    # Affichage des rÃ©sultats
    if strategy == "mixed" and isinstance(recommendations, dict):
        show_mixed_recommendations(recommendations, user_input)
    else:
        show_unified_recommendations(recommendations, user_input)

def show_unified_recommendations(recommendations, user_input):
    """Affiche les recommandations unifiÃ©es"""
    
    st.header("ğŸ“‹ Vos Recommandations PersonnalisÃ©es")
    
    if recommendations.empty:
        st.warning("""
        ğŸ¤” Aucune recommandation ne correspond exactement Ã  vos critÃ¨res.
        
        **Suggestions :**
        - Ã‰largissez vos filtres de recherche
        - RÃ©duisez la note minimale requise  
        - Essayez d'autres mots-clÃ©s
        - Consultez les cours tendances ci-dessous
        """)
        
        # Fallback: cours tendances
        st.subheader("ğŸ”¥ Cours Tendances (Alternative)")
        trending = st.session_state.recommender.knowledge_recommender.get_trending_courses(10)
        display_courses_grid(trending, user_input, show_explanation=False)
        return
    
    # MÃ©triques des rÃ©sultats
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ¯ Cours TrouvÃ©s", len(recommendations))
    with col2:
        st.metric("â­ Note Moyenne", f"{recommendations['rating'].mean():.2f}")
    with col3:
        avg_duration = f"{recommendations['duration_weeks'].mean():.1f} semaines"
        st.metric("ğŸ“… DurÃ©e Moyenne", avg_duration)
    with col4:
        best_rating = recommendations['rating'].max()
        st.metric("ğŸ† Meilleure Note", f"{best_rating:.1f}")
    
    st.markdown("---")
    
    # Affichage des cours
    display_courses_grid(recommendations, user_input)

def show_mixed_recommendations(recommendations_dict, user_input):
    """Affiche les recommandations par catÃ©gorie (stratÃ©gie mixte)"""
    
    st.header("ğŸ­ Recommandations par CatÃ©gorie")
    
    tabs = st.tabs(["ğŸ” SÃ©mantique", "ğŸ“ Knowledge-Based", "â¤ï¸ Collaboratif", "ğŸ”¥ Tendance"])
    
    with tabs[0]:
        if 'content_based' in recommendations_dict and not recommendations_dict['content_based'].empty:
            st.subheader("BasÃ© sur votre recherche sÃ©mantique")
            display_courses_grid(recommendations_dict['content_based'], user_input)
        else:
            st.info("Aucune recommandation sÃ©mantique. Essayez d'ajouter une description de recherche.")
    
    with tabs[1]:
        if 'knowledge_based' in recommendations_dict and not recommendations_dict['knowledge_based'].empty:
            st.subheader("BasÃ© sur vos filtres et contraintes")
            display_courses_grid(recommendations_dict['knowledge_based'], user_input)
        else:
            st.info("Aucun cours ne correspond Ã  tous vos filtres. Essayez de les assouplir.")
    
    with tabs[2]:
        if 'collaborative' in recommendations_dict and not recommendations_dict['collaborative'].empty:
            st.subheader("BasÃ© sur vos cours prÃ©fÃ©rÃ©s")
            display_courses_grid(recommendations_dict['collaborative'], user_input)
        else:
            st.info("SÃ©lectionnez des cours que vous avez aimÃ©s pour des recommandations collaboratives.")
    
    with tabs[3]:
        if 'trending' in recommendations_dict and not recommendations_dict['trending'].empty:
            st.subheader("Cours populaires en ce moment")
            display_courses_grid(recommendations_dict['trending'], user_input, show_explanation=False)
        else:
            st.info("Chargement des cours tendances...")

# MODIFIEZ la fonction display_courses_grid comme suit :
def display_courses_grid(courses_df, user_input, show_explanation=True):
    """Affiche une grille de cours avec leurs dÃ©tails"""
    
    if courses_df.empty:
        st.write("Aucun cours Ã  afficher.")
        return
    
    max_values = {
        'max_reviews': courses_df['number_of_review'].max(),
        'max_duration': courses_df['duration_weeks'].max()
    }
    
    for idx, course in courses_df.iterrows():
        with st.container():
            # Header du cours
            col_header1, col_header2 = st.columns([3, 1])
            
            with col_header1:
                st.subheader(f"ğŸ“š {course['course_title']}")
            
            with col_header2:
                # Badges
                col_b1, col_b2, col_b3 = st.columns(3)
                with col_b1:
                    st.metric("â­", f"{course['rating']:.1f}")
                with col_b2:
                    st.metric("ğŸ‘¥", f"{course['number_of_review']}")
                with col_b3:
                    st.metric("ğŸ“…", f"{int(course['duration_weeks'])}s")
            
            # Informations dÃ©taillÃ©es
            col_info1, col_info2 = st.columns([2, 1])
            
            with col_info1:
                st.write(f"**ğŸ¢ Organisme :** {course['offered_by']}")
                st.write(f"**ğŸ‘¨â€ğŸ« Instructeur :** {course['instructor']}")
                st.write(f"**ğŸ¯ Niveau :** {course['level']}")
                st.write(f"**ğŸ› ï¸ CompÃ©tences :** {course['skill_gain']}")
                
                if 'what_you_will_learn' in course and pd.notna(course['what_you_will_learn']) and course['what_you_will_learn'] != '':
                    with st.expander("ğŸ“– Ce que vous apprendrez"):
                        st.write(course['what_you_will_learn'])
            
            with col_info2:
                # UTILISATION DE LA NOUVELLE FONCTION AVEC CLÃ‰ UNIQUE
                chart_key = f"radar_{course['course_title'][:20]}_{idx}"
                display_radar_chart(course, max_values, chart_key)
            
            # Lien vers le cours
            if 'course_url' in course and pd.notna(course['course_url']):
                st.markdown(f"[ğŸ”— AccÃ©der au cours sur Coursera]({course['course_url']})")
            
            # Explication de la recommandation
            if show_explanation:
                with st.expander("ğŸ’¡ Pourquoi ce cours vous est recommandÃ©", expanded=False):
                    explanation = generate_explanation(course, user_input)
                    st.write(explanation)
            
            st.markdown("---")

def parse_duration(duration_str):
    """Convertit la durÃ©e en semaines"""
    if duration_str == "All":
        return None
    elif duration_str == "20+ weeks":
        return 20
    else:
        return int(duration_str.split()[0])

# =============================================================================
# POINT D'ENTRÃ‰E
# =============================================================================

if __name__ == "__main__":
    main()